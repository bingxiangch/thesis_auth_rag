# The default configuration file.
server:
  env_name: ${APP_ENV:prod}
  port: ${PORT:8001}
  cors:
    enabled: true
    allow_origins: ["*"]
    allow_methods: ["*"]
    allow_headers: ["*"]

data:
  local_data_folder: local_data/auth_RAG


database:
  type: sqlite
  url: sqlite:///./sqlite.db

system_prompt:
  default_query_system_prompt: >
    As an intelligent assistant, You can only answer questions about patient profiles from the provided context. If you know the answer but it is not based on the provided context, don't provide the answer, just state the answer is not in the context provided. Ensuring precision and relevance in your responses. Please ensure that your answers to patient questions are based on the respective user's name. Keep sources and responses separate, ensuring thorough comparison. When listing symptoms, present each patient's details separately for accuracy. Ensure accuracy by acknowledging individual symptoms unique to each patient, and explicitly mentioning variations to avoid generalizations. 
llm:
  mode: local
  # Should be matching the selected model
  max_new_tokens: 512
  context_window: 3900
  tokenizer: mistralai/Mistral-7B-Instruct-v0.2

embedding:
  # Should be matching the value above in most cases
  mode: local
  ingest_mode: simple

vectorstore:
  database: chroma

local:
  prompt_style: "mistral"
  llm_hf_repo_id: TheBloke/Mistral-7B-Instruct-v0.2-GGUF
  llm_hf_model_file: mistral-7b-instruct-v0.2.Q4_K_M.gguf
  embedding_hf_model_name: BAAI/bge-small-en-v1.5

