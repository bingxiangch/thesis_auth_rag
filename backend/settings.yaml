# The default configuration file.
server:
  env_name: ${APP_ENV:prod}
  port: ${PORT:8001}
  cors:
    enabled: true
    allow_origins: ["*"]
    allow_methods: ["*"]
    allow_headers: ["*"]

data:
  local_data_folder: local_data/auth_RAG


database:
  type: sqlite
  url: sqlite:///./sqlite.db

system_prompt:
  default_query_system_prompt: >
    You can only answer questions about the provided context. If you know the answer but it is not based on the provided context, just state 'I don't know the answer from the context provided.'. Ensure that your answers to patient questions are personalized with the respective patient's name.

embedding:
  # Should be matching the value above in most cases
  mode: local
  ingest_mode: simple

vectorstore:
  database: chroma


llm:
  mode: local #support the three options: local, openai, and azureOpenai
  # Should be matching the selected model
  max_new_tokens: 512
  context_window: 3900
  tokenizer: mistralai/Mistral-7B-Instruct-v0.2


local:
  prompt_style: "mistral"
  llm_hf_repo_id: TheBloke/Mistral-7B-Instruct-v0.2-GGUF
  llm_hf_model_file: mistral-7b-instruct-v0.2.Q4_K_M.gguf
  embedding_hf_model_name: BAAI/bge-small-en-v1.5
  access_token: hf_token

openai:
  api_key: api_key
  model: gpt-3.5-turbo

azure:
  model: gpt-4
  deployment_name: YOUR_DEPLOYMENT_NAME
  api_key: API_KEY #api_key
  azure_endpoint: YOUR_AZURE_OPENAI
  api_version: '2024-02-15-preview'
